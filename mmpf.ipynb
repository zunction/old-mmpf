{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(dataset = '16-50K.npy', borrow = True):\n",
    "    \"\"\"\n",
    "    Loads the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.load(dataset)\n",
    "    dataset = theano.shared(np.asarray(data, dtype = theano.config.floatX), borrow = borrow)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "class mpf(object):\n",
    "    \"\"\"\n",
    "    Minimum probability flow\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input = None, n = 16, W = None, b = None):\n",
    "        \"\"\"\n",
    "        Initialize mpf class\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "\n",
    "        U = np.random.rand(self.n, self.n)\n",
    "        R = 0.5 * (U + U.T)\n",
    "        np.fill_diagonal(R, 0)\n",
    "\n",
    "        if not W:\n",
    "            initial_W = np.asarray(R, dtype = theano.config.floatX)\n",
    "            W = theano.shared(initial_W, name = 'W', borrow = True)\n",
    "\n",
    "        if not b:\n",
    "            initial_b = np.asarray(np.random.rand(n), dtype = theano.config.floatX)\n",
    "            b = theano.shared(initial_b, name = 'b', borrow = True)\n",
    "\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "#         self.input = input\n",
    "        if input is None:\n",
    "            self.x = T.dmatrix(name = 'input')\n",
    "        else:\n",
    "            self.x = input\n",
    "\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "\n",
    "    def Kcost(self, learning_rate = 10e-2):\n",
    "        \"\"\"\n",
    "        Returns the cost\n",
    "        \"\"\"\n",
    "\n",
    "        cost = T.mean(T.exp((0.5 - self.x) * (T.dot(self.x, self.W) + self.b)))\n",
    "#         gparams = T.grad(cost, self.params)\n",
    "#         updates = [(param, param - learning_rate * gparam) for param, gparam in zip(self.params, gparams)]\n",
    "        Wgrad = T.grad(cost, self.W)\n",
    "#         T.fill_diagonal(Wgrad, 0)\n",
    "        bgrad = T.grad(cost, self.b)\n",
    "\n",
    "        Wupdate = T.fill_diagonal(0.5 * ((self.W - learning_rate * Wgrad) + (self.W - learning_rate * Wgrad).T), 0)\n",
    "        updates = [(self.W, Wupdate), (self.b, self.b - learning_rate * bgrad )]\n",
    "#         updates = [(self.W, self.W - learning_rate * Wgrad), (self.b, self.b - learning_rate * bgrad )]\n",
    "\n",
    "        return cost, updates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd(units = 16, learning_rate = 10e-2, n_epochs = 1000, batch_size = 16,  sample = '16-50K.npy'):\n",
    "    \"\"\"\n",
    "    Perform stochastic gradient descent on MPF\n",
    "    \"\"\"\n",
    "    print ('Loading '+ 'sample' + '...')\n",
    "\n",
    "    dataset = load_data(sample)\n",
    "\n",
    "    n_dataset_batches = dataset.get_value(borrow = True).shape[0] // batch_size\n",
    "\n",
    "    print ('Building the model...')\n",
    "\n",
    "    index = T.lscalar()\n",
    "    x = T.matrix('x')\n",
    "\n",
    "#     if not os.path.isdir(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "#     os.chdir(output_folder)\n",
    "\n",
    "    flow = mpf(input = x, n = units)\n",
    "    cost, updates = flow.Kcost()\n",
    "\n",
    "    train_mpf = theano.function(inputs = [index], outputs = cost, updates = updates, \\\n",
    "                                givens = {x: dataset[index * batch_size: (index + 1) * batch_size]})\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        c = []\n",
    "        current_time = timeit.default_timer()\n",
    "        for batch_index in range(n_dataset_batches):\n",
    "            c.append(train_mpf(batch_index))\n",
    "\n",
    "        print ('Training epoch %d, Cost: %f, Time Elasped: %.2f' % (epoch, np.mean(c, dtype='float64'), (current_time - start_time)/60) )\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    print ('The training took %.2f minutes' % (training_time/60.))\n",
    "\n",
    "    W_learnt = flow.W.get_value(borrow = True)\n",
    "    b_learnt = flow.b.get_value(borrow = True)\n",
    "    W = np.load(sample[0:2] + '-' + 'W' + '.npy')\n",
    "    b = np.load(sample[0:2] + '-' + 'b' + '.npy')\n",
    "\n",
    "    fnormW = np.linalg.norm(W - W_learnt)\n",
    "    fnormb = np.linalg.norm(b - b_learnt)\n",
    "\n",
    "    print ('Comparing the parameters learnt...')\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].plot(W.reshape(-1,1)[0:100], 'b')\n",
    "    ax[0].plot(W_learnt.reshape(-1,1)[0:100], 'r')\n",
    "    ax[0].set_title('Weight matrix, W')\n",
    "    ax[0].legend(['W', 'Learnt W'])\n",
    "    ax[1].plot(b.reshape(-1,1), 'b')\n",
    "    ax[1].plot(b_learnt.reshape(-1,1),'r')\n",
    "    ax[1].set_title('Bias, b')\n",
    "    ax[1].legend(['b', 'Learnt b'])\n",
    "    \n",
    "    E = epoch // 1000\n",
    "    \n",
    "    savefilename = sample[:-4] + '-' + str(learning_rate)+ '-' + str(E) + 'K-' + str(batch_size) + '-'\n",
    "\n",
    "    \n",
    "    print ('Frobenius norm (W): %f' % fnormW)\n",
    "    print ('Frobenius norm (b): %f' % fnormb)\n",
    "    \n",
    "    i = 0\n",
    "    while os.path.exists('{}{:d}.png'.format(savefilename, i)):\n",
    "        i += 1\n",
    "    \n",
    "    plt.savefig('{}{:d}.png'.format(savefilename, i))\n",
    "    print ('Saving plots to ' + '{}{:d}.png'.format(savefilename, i))\n",
    "\n",
    "    return W_learnt, b_learnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_learnt, b_learnt = sgd(units = 16, learning_rate = 1e-2, n_epochs = 10, batch_size = 16,  sample = '16-50K.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run mmpf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
